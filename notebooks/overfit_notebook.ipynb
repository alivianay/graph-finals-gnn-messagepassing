{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "140975fd",
   "metadata": {},
   "source": [
    "# Import Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8615690",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch_geometric.datasets import Planetoid\n",
    "from torch_geometric.loader import NeighborLoader\n",
    "from torch_geometric.nn import MessagePassing\n",
    "from torch_geometric.utils import to_networkx, subgraph, k_hop_subgraph\n",
    "from torch_geometric.nn import GCNConv, GATConv, SAGEConv, GINConv\n",
    "from torch_geometric.data import Data\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2781b26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set random seeds for reproducibility\n",
    "torch.manual_seed(42)\n",
    "np.random.seed(42)\n",
    "random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94cfa320",
   "metadata": {},
   "outputs": [],
   "source": [
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed_all(42)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2014b629",
   "metadata": {},
   "source": [
    "# Load Cora Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d0da986",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = Planetoid(root=\"../data/Cora\", name=\"Cora\")\n",
    "data = dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c42436f",
   "metadata": {},
   "outputs": [],
   "source": [
    "node_of_interest = random.randint(0, data.num_nodes - 1)\n",
    "print(\"Node of Interest:\", node_of_interest)\n",
    "\n",
    "# extract 2-hop subgraph\n",
    "subset_nodes, sub_edge_index, _, _ = k_hop_subgraph(\n",
    "    node_of_interest, \n",
    "    num_hops=2, \n",
    "    edge_index=data.edge_index, \n",
    "    relabel_nodes=True\n",
    ")\n",
    "\n",
    "sub_x = data.x[subset_nodes]\n",
    "sub_y = data.y[subset_nodes]\n",
    "\n",
    "print(\"Subgraph Nodes:\", sub_x.size(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8af532b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# G = to_networkx(\n",
    "#     Data(x=sub_x, edge_index=sub_edge_index), \n",
    "#     to_undirected=True\n",
    "# )\n",
    "\n",
    "# plt.figure(figsize=(6,6))\n",
    "# nx.draw(G, node_size=50)\n",
    "# plt.title(\"Subgraph (2-hop Neighborhood)\")\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3aad5c45",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Jumlah Node\n",
    "data.num_nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efd9fea9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#jumlah edge\n",
    "data.num_edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82bfe904",
   "metadata": {},
   "outputs": [],
   "source": [
    "#dimensi fitur\n",
    "data.num_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09a67396",
   "metadata": {},
   "outputs": [],
   "source": [
    "#jumlah keasl\n",
    "dataset.num_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4411976e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#nama kelas\n",
    "data.y.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a19ceca3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#nodes belong to classes\n",
    "data.y.bincount()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f554d39",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_counts = data.y.bincount()\n",
    "for class_idx in range(len(class_counts)):\n",
    "    print(f\"Kelas {class_idx}: {class_counts[class_idx].item()} nodes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c3f934e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_counts = data.y.bincount()\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Bar plot of class distribution\n",
    "axes[0].bar(range(len(class_counts)), class_counts.numpy())\n",
    "axes[0].set_xlabel('Class')\n",
    "axes[0].set_ylabel('Number of Nodes')\n",
    "axes[0].set_title('Class Distribution in Cora Dataset')\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "# Pie chart of class distribution\n",
    "colors = plt.cm.Set3(np.linspace(0, 1, len(class_counts)))\n",
    "axes[1].pie(class_counts.numpy(), labels=[f'Class {i}' for i in range(len(class_counts))], \n",
    "            autopct='%1.1f%%', colors=colors)\n",
    "axes[1].set_title('Class Distribution (Percentage)')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5e53bdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#train nodes\n",
    "data.train_mask.sum().item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "252f2c97",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"\\nTrain ratio: {data.train_mask.sum().item()/data.num_nodes:.2%}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f39eeac",
   "metadata": {},
   "outputs": [],
   "source": [
    "#validation nodes\n",
    "data.val_mask.sum().item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3473e1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Validation ratio: {data.val_mask.sum().item()/data.num_nodes:.2%}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15ce8961",
   "metadata": {},
   "outputs": [],
   "source": [
    "#test nodes\n",
    "data.test_mask.sum().item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ceba616d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Test ratio: {data.test_mask.sum().item()/data.num_nodes:.2%}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4160fb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.edge_index.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca63bc68",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.edge_index[:, :5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0c3c4e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.x[0, :10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87bcf9d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "node_of_interest = 100  # Fixed for consistent visualization\n",
    "print(f\"Node of Interest: {node_of_interest} (Class: {data.y[node_of_interest].item()})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c7c917d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract 2-hop subgraph\n",
    "subset_nodes, sub_edge_index, mapping, _ = k_hop_subgraph(\n",
    "    node_of_interest, \n",
    "    num_hops=2, \n",
    "    edge_index=data.edge_index, \n",
    "    relabel_nodes=True,\n",
    "    num_nodes=data.num_nodes\n",
    ")\n",
    "\n",
    "sub_x = data.x[subset_nodes]\n",
    "sub_y = data.y[subset_nodes]\n",
    "\n",
    "print(f\"Subgraph contains {sub_x.size(0)} nodes\")\n",
    "print(f\"Classes in subgraph: {torch.unique(sub_y).tolist()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22798b81",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to NetworkX for visualization\n",
    "subgraph_data = Data(x=sub_x, edge_index=sub_edge_index)\n",
    "G = to_networkx(subgraph_data, to_undirected=True)\n",
    "\n",
    "plt.figure(figsize=(12, 10))\n",
    "\n",
    "# Create color map for classes\n",
    "cmap = plt.cm.tab10\n",
    "node_colors = [cmap(y) for y in sub_y.numpy()]\n",
    "\n",
    "# Get positions using spring layout\n",
    "pos = nx.spring_layout(G, seed=42, k=1)\n",
    "\n",
    "# Highlight the center node\n",
    "center_idx = (subset_nodes == node_of_interest).nonzero(as_tuple=True)[0].item()\n",
    "\n",
    "# Draw the graph\n",
    "nx.draw_networkx_nodes(G, pos, node_size=300, \n",
    "                       node_color=node_colors, \n",
    "                       alpha=0.8, \n",
    "                       linewidths=0.5,\n",
    "                       edgecolors='black')\n",
    "nx.draw_networkx_edges(G, pos, width=1.0, alpha=0.5, edge_color='gray')\n",
    "\n",
    "# Highlight center node\n",
    "nx.draw_networkx_nodes(G, pos, nodelist=[center_idx], \n",
    "                       node_size=500, \n",
    "                       node_color='red',\n",
    "                       edgecolors='black', \n",
    "                       linewidths=2)\n",
    "\n",
    "# Add labels for the center node\n",
    "labels = {center_idx: 'Center'}\n",
    "nx.draw_networkx_labels(G, pos, labels, font_size=12, font_weight='bold')\n",
    "\n",
    "plt.title(f\"2-hop Neighborhood of Node {node_of_interest}\\n(Class {data.y[node_of_interest].item()})\", fontsize=14)\n",
    "plt.axis('off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d632ecce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from matplotlib.patches import Patch\n",
    "# legend_elements = [Patch(facecolor=cmap(i), label=f'Class {i}') \n",
    "#                    for i in range(dataset.num_classes)]\n",
    "# plt.legend(handles=legend_elements, loc='upper right', title=\"Classes\")\n",
    "\n",
    "# plt.tight_layout()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bb40676",
   "metadata": {},
   "outputs": [],
   "source": [
    "degrees = np.zeros(data.num_nodes)\n",
    "for i in range(data.num_nodes):\n",
    "    degrees[i] = (data.edge_index[0] == i).sum().item()\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Histogram of degree distribution\n",
    "axes[0].hist(degrees, bins=50, edgecolor='black', alpha=0.7)\n",
    "axes[0].set_xlabel('Degree')\n",
    "axes[0].set_ylabel('Frequency')\n",
    "axes[0].set_title('Degree Distribution Histogram')\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "# Log-log plot for power law check\n",
    "unique_degrees, degree_counts = np.unique(degrees, return_counts=True)\n",
    "axes[1].loglog(unique_degrees, degree_counts, 'bo', alpha=0.7)\n",
    "axes[1].set_xlabel('Degree (log)')\n",
    "axes[1].set_ylabel('Frequency (log)')\n",
    "axes[1].set_title('Degree Distribution (Log-Log Scale)')\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "366c5a21",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"• Average degree: {degrees.mean():.2f}\")\n",
    "print(f\"• Maximum degree: {degrees.max():.0f}\")\n",
    "print(f\"• Minimum degree: {degrees.min():.0f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e9dd695",
   "metadata": {},
   "source": [
    "# PRA-PROSES (Message Passing Layer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6802e7c0",
   "metadata": {},
   "source": [
    "$h_u^{(k)} = \\sum W_{\\text{msg}} \\cdot h_u^{(k-1)} + W_{\\text{self}} \\cdot h_v^{(k-1)}$\n",
    "\n",
    " di mana,\n",
    " 1. **k** adalah urutan lapisan GNN.\n",
    " 2. **Wmsg** adalah bobot yang diakses bersama dengan neighborhood nodes.\n",
    " 3. **Wself** adalah bobot milik node asal (v)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5031c345",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomMessagePassing(MessagePassing):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super().__init__(aggr='add')\n",
    "        self.W_msg = nn.Linear(in_channels, out_channels)  # For neighbors\n",
    "        self.W_self = nn.Linear(in_channels, out_channels) # For self\n",
    "        \n",
    "    def forward(self, x, edge_index):\n",
    "        return self.propagate(edge_index, x=x)\n",
    "    \n",
    "    def message(self, x_j):\n",
    "        return self.W_msg(x_j)\n",
    "    \n",
    "    def update(self, aggr_out, x):\n",
    "        return aggr_out + self.W_self(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e63df00",
   "metadata": {},
   "outputs": [],
   "source": [
    "# class CustomMessagePassing(MessagePassing):\n",
    "#     def __init__(self, in_channels, out_channels, aggr='add'):\n",
    "#         super().__init__(aggr=aggr)\n",
    "#         self.W_msg = nn.Linear(in_channels, out_channels)\n",
    "#         self.W_self = nn.Linear(in_channels, out_channels)\n",
    "        \n",
    "#     def forward(self, x, edge_index):\n",
    "#         return self.propagate(edge_index, x=x)\n",
    "    \n",
    "#     def message(self, x_j):\n",
    "#         return self.W_msg(x_j)\n",
    "    \n",
    "#     def update(self, aggr_out, x):\n",
    "#         return aggr_out + self.W_self(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c1a6f14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TEST MESSAGE PASSING\n",
    "\n",
    "test_mp = CustomMessagePassing(in_channels=16, out_channels=32)\n",
    "test_mp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "291edd7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_mp.W_msg.weight.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e808fdc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_mp.W_self.weight.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a67b000",
   "metadata": {},
   "source": [
    "# Intra-layer GNN Block"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aaffddfc",
   "metadata": {},
   "source": [
    "$$\n",
    "\\mathbf{h}_v^{(k)} =\n",
    "\\text{ACT}\\!\\left(\n",
    "    \\text{Dropout}\\!\\left(\n",
    "        \\text{BatchNorm}\\!\\left(\n",
    "            \\mathbf{W}^{(k-1)}\\,\\mathbf{h}_v^{(k-1)} + \\mathbf{b}^{(k-1)}\n",
    "        \\right)\n",
    "    \\right)\n",
    "\\right)\n",
    "+ \\mathbf{h}_v^{(k-1)}\n",
    "$$\n",
    "\n",
    "\n",
    "di mana:\n",
    "\n",
    "1. **ACT** adalah fungsi aktivasi yang Anda pilih.\n",
    "2. **BatchNorm** adalah `1D-Batch Normalization`.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3564282d",
   "metadata": {},
   "source": [
    "## DEFINE SINGLE GNN LAYER "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bba61c15",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GNNLayer(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, dropout=0.5):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.message_passing = CustomMessagePassing(in_channels, out_channels)\n",
    "        \n",
    "        # Post-message-passing processing\n",
    "        self.linear = nn.Linear(out_channels, out_channels)\n",
    "        self.batch_norm = nn.BatchNorm1d(out_channels)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.activation = nn.ReLU()\n",
    "        \n",
    "        # Residual connection\n",
    "        if in_channels != out_channels:\n",
    "            self.residual = nn.Linear(in_channels, out_channels)\n",
    "        else:\n",
    "            self.residual = nn.Identity()\n",
    "    \n",
    "    def forward(self, x, edge_index):\n",
    "        x_input = x\n",
    "        \n",
    "        # Message passing\n",
    "        x_mp = self.message_passing(x, edge_index)\n",
    "        \n",
    "        # Process features\n",
    "        x_linear = self.linear(x_mp)\n",
    "        x_bn = self.batch_norm(x_linear)\n",
    "        x_drop = self.dropout(x_bn)\n",
    "        x_act = self.activation(x_drop)\n",
    "        \n",
    "        # Residual connection\n",
    "        x_residual = self.residual(x_input)\n",
    "        return x_act + x_residual"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1253f96d",
   "metadata": {},
   "source": [
    "## Test GNN Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8daa636a",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_layer = GNNLayer(in_channels=16, out_channels=32)\n",
    "test_layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d4b7804",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_layer.batch_norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f7b8cd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_layer.dropout.p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21443775",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_layer.activation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "211bf83f",
   "metadata": {},
   "source": [
    "# Full Model with k>1 Layers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4992ca90",
   "metadata": {},
   "source": [
    "## Build Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a00277a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GNNModel(nn.Module):\n",
    "    def __init__(self, in_channels, hidden_channels, out_channels, num_classes, num_layers, dropout=0.6):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.input_proj = nn.Sequential(\n",
    "            nn.Linear(in_channels, hidden_channels),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout)  # Increase dropout\n",
    "        )\n",
    "        \n",
    "        self.layers = nn.ModuleList()\n",
    "        for i in range(num_layers - 1):\n",
    "            self.layers.append(\n",
    "                GCNConv(hidden_channels, hidden_channels)\n",
    "            )\n",
    "        \n",
    "        self.layers.append(\n",
    "            GCNConv(hidden_channels, out_channels)\n",
    "        )\n",
    "        \n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(out_channels, num_classes),\n",
    "            nn.LogSoftmax(dim=1)\n",
    "        )\n",
    "        \n",
    "    def forward(self, x, edge_index):\n",
    "        x = self.input_proj(x)\n",
    "        \n",
    "        for i, layer in enumerate(self.layers):\n",
    "            x = layer(x, edge_index)\n",
    "            x = F.relu(x)\n",
    "            x = F.dropout(x, p=0.6, training=self.training)  # Increase dropout\n",
    "        \n",
    "        return self.classifier(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17701627",
   "metadata": {},
   "source": [
    "## Initialize Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5aa8b5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd45fbe2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = GNNModel(\n",
    "#     in_channels=data.num_features,\n",
    "#     hidden_channels=512,\n",
    "#     out_channels=dataset.num_classes\n",
    "# ).to(device)\n",
    "\n",
    "# print(f\"Model created on {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fee515e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = GNNModel(\n",
    "#     in_channels=data.num_features,\n",
    "#     hidden_channels=256,\n",
    "#     out_channels=dataset.num_classes\n",
    "# ).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b251e0fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "out_classes = dataset.num_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0370e27",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = GNNModel(\n",
    "    in_channels=1433,\n",
    "    hidden_channels=128,\n",
    "    out_channels=128,\n",
    "    num_classes=7,\n",
    "    num_layers=2,  # Reduced from 4\n",
    "    dropout=0.6\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3861ba1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Increase weight decay\n",
    "# optimizer = torch.optim.Adam(model.parameters(), lr=0.01, weight_decay=5e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1026dcef",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.AdamW(model.parameters(), \n",
    "                             lr=0.01, \n",
    "                             weight_decay=5e-4,  # L2 regularization\n",
    "                             betas=(0.9, 0.999))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cafc3706",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.classifier = nn.Linear(128, out_classes).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0270bff",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.classifier = nn.Linear(128, out_classes).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6e9e297",
   "metadata": {},
   "outputs": [],
   "source": [
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
    "    optimizer, \n",
    "    mode='max',\n",
    "    factor=0.5,\n",
    "    patience=20,\n",
    "    min_lr=1e-5,\n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "490e0140",
   "metadata": {},
   "source": [
    "## RAINING LOOP WITH VALIDATION LOSS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7da80ca1",
   "metadata": {},
   "source": [
    "### DEFINE TRAINING STEP FUNCTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c60dbaea",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_one_epoch(model, data, optimizer, smoothing=0.1):\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    out = model(data.x, data.edge_index)\n",
    "    \n",
    "    # Label smoothing\n",
    "    n_classes = out.size(1)\n",
    "    target = data.y[data.train_mask]\n",
    "    target_onehot = torch.zeros_like(out[data.train_mask]).scatter_(1, target.unsqueeze(1), 1)\n",
    "    target_smoothed = target_onehot * (1 - smoothing) + smoothing / n_classes\n",
    "    \n",
    "    loss = F.kl_div(F.log_softmax(out[data.train_mask], dim=1), \n",
    "                   target_smoothed, \n",
    "                   reduction='batchmean')\n",
    "    \n",
    "    loss.backward()\n",
    "    torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "    optimizer.step()\n",
    "    \n",
    "    return loss.item()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "923f2536",
   "metadata": {},
   "source": [
    "### DEFINE EVALUATION FUNCTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40bcbd33",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, data, mask):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        out = model(data.x, data.edge_index)\n",
    "        pred = out[mask].argmax(dim=1)\n",
    "        correct = (pred == data.y[mask]).sum().item()\n",
    "        accuracy = correct / mask.sum().item()\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0c7cbbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03993c01",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define number of epochs\n",
    "epochs = 300  # or whatever number you want"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "806e6328",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Also define other variables\n",
    "patience = 100\n",
    "train_losses = []\n",
    "val_accuracies = []\n",
    "test_accuracies = []\n",
    "best_val_acc = 0.0\n",
    "patience_counter = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99eef4df",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = model.to(device)\n",
    "\n",
    "# Move data\n",
    "data = data.to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b3ce693",
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(epochs):\n",
    "    # 1. Training\n",
    "    loss = train_one_epoch(model, data, optimizer)\n",
    "    train_losses.append(loss)\n",
    "    \n",
    "    # 2. Evaluation (compute val_acc and test_acc) - DO THIS FIRST\n",
    "    val_acc = evaluate(model, data, data.val_mask)\n",
    "    test_acc = evaluate(model, data, data.test_mask)\n",
    "    \n",
    "    val_accuracies.append(val_acc)\n",
    "    test_accuracies.append(test_acc)\n",
    "    \n",
    "    # 3. Update scheduler - NOW val_acc is defined!\n",
    "    scheduler.step(val_acc)  # ← Now this works\n",
    "    \n",
    "    # 4. Early stopping check\n",
    "    if val_acc > best_val_acc:\n",
    "        best_val_acc = val_acc\n",
    "        patience_counter = 0\n",
    "        torch.save(model.state_dict(), '../models/best_model.pth')\n",
    "    else:\n",
    "        patience_counter += 1\n",
    "    \n",
    "    # 5. Progress reporting\n",
    "    if epoch % 10 == 0:\n",
    "        lr = optimizer.param_groups[0]['lr']\n",
    "        print(f'Epoch {epoch:3d}: Loss={loss:.4f}, Val={val_acc:.4f}, Test={test_acc:.4f}, LR={lr:.6f}')\n",
    "    \n",
    "    # 6. Early stopping condition\n",
    "    if patience_counter >= patience:\n",
    "        print(f'\\nEarly stopping at epoch {epoch}')\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a861b663",
   "metadata": {},
   "outputs": [],
   "source": [
    "# In training loop:\n",
    "scheduler.step(val_acc)  # Pass validation accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27e10bca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load best model\n",
    "model.load_state_dict(torch.load('../models/best_model.pth'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62ee99b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    out = model(data.x, data.edge_index)\n",
    "    \n",
    "    # Calculate final accuracies\n",
    "    train_pred = out[data.train_mask].argmax(dim=1)\n",
    "    train_acc = (train_pred == data.y[data.train_mask]).float().mean().item()\n",
    "    \n",
    "    val_pred = out[data.val_mask].argmax(dim=1)\n",
    "    val_acc = (val_pred == data.y[data.val_mask]).float().mean().item()\n",
    "    \n",
    "    test_pred = out[data.test_mask].argmax(dim=1)\n",
    "    test_acc = (test_pred == data.y[data.test_mask]).float().mean().item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a55d5ec1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleGCN(nn.Module):\n",
    "    def __init__(self, in_channels, hidden_channels, num_classes, dropout=0.5):\n",
    "        super().__init__()\n",
    "        self.conv1 = GCNConv(in_channels, hidden_channels)\n",
    "        self.conv2 = GCNConv(hidden_channels, num_classes)\n",
    "        self.dropout = dropout\n",
    "        \n",
    "    def forward(self, x, edge_index):\n",
    "        x = self.conv1(x, edge_index)\n",
    "        x = F.relu(x)\n",
    "        x = F.dropout(x, p=self.dropout, training=self.training)\n",
    "        x = self.conv2(x, edge_index)\n",
    "        return F.log_softmax(x, dim=1)\n",
    "\n",
    "model = SimpleGCN(\n",
    "    in_channels=1433,\n",
    "    hidden_channels=16,  # Smaller hidden dimension\n",
    "    num_classes=7,\n",
    "    dropout=0.6\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gnn-cora",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
